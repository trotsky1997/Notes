[TOC]



# 凸函数

主讲:小龙老师

![image-20200718172413617](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718172413617.png)

## 课程介绍

AI的发展趋势:从研究人员到大众



![image-20200718120115869](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718120115869.png)

arxiv是其中更新最快的渠道.

## 优化的概念

![image-20200718125357199](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718125357199.png)

optimization is the core of machine learning.

![image-20200718125900826](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718125900826.png)

线性回归（Linear regression）:$\left.\begin{array}{c}
\min\sum_{i=1}^{n}\left(w^{\top} x_{i}-y_{z}\right)^{2}+\| w_{i}^{2}\| \\
\min\left\|x w-y_{2}^{2}\|+\right \| w \|_{2}^{2}
\end{array}\right\}$

逻辑回归(Logistic regression):

支持向量机(support vector machine):$\left.\begin{array}\left \|w\|_2^2+\lambda\sum_{i=1}^n{a_i} \}\\ s.t. a_i \geq 1- a_i(w^TX+b) \end{array}\right\}$

协同过滤(Collaborative Filtering)

K-means:

![image-20200718142547232](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718142547232.png)

![image-20200718143345866](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718143345866.png)

优化问题分类:

1.  convex v.s non-convex 凸 非凸

    凸函数:开口向上

    局部极值点 local optimized value

2.  连续 离散

3.  有限制条件 无限制条件

4.  光滑 不光滑

complex可计算性和计算复杂度问题

NP-hard:$o(d^n)$ Exponential 指数时间复杂度

NP:$o(n^C),C为常数$ Polynomal 线性时间复杂度

![image-20200718144040120](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718144040120.png)

凸优化基本形式:![image-20200718144054048](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718144054048.png)



![image-20200718144128440](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718144128440.png)

在区域内任取两点连线,线上任一点任然在区域内.

 

![image-20200718144558899](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718144558899.png)

![image-20200718144643287](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718144643287.png)

![image-20200718153222971](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718153222971.png)

jensen不等式:

对于凸函数$f(x)$,有$\forall \lambda_i >0,\sum\lambda_i = 1$满足$f(\sum_{i=1}^M\lambda_ix_i) \leq\sum_{i=1}^M{\lambda_if(x_i)}$

![image-20200718154010775](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718154010775.png)

范数(Norm):

$L_p$ 正则:$$\|w\|_p = (\sum w_i^p)^{\frac{1}{p}}$$

L0正则:

L1正则:

L2正则:

$L_\infin$正则:

![image-20200718154250321](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718154250321.png)

![image-20200718154511485](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718154511485.png)

若函数$f$的海塞矩阵(二阶导数矩阵)在定义域上任一点都是半正定(PSD posite-semidefinite)矩阵,则函数f是凸函数.

引入SDP (半正定规划):*semi*-*definite* programming

线性函数是凸函数:

![image-20200718154924337](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718154924337.png)

二次方函数是凸函数:

![image-20200718155151377](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718155151377.png)

### 小作业:

证明L2范数或sigmoid函数是凸函数.

-   矩阵运算参考:https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf

##transportation problem



1.  选取变量

2.  选取优化目标函数

3.  确定约束关系

4.  判断目标类型

5.  设计算法解决

    

![image-20200718160934854](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718160934854.png)



![image-20200718161049081](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718161049081.png)

得到约束组后使用`线性规划`(Linear programming)解决.

在约束数量较大时,引入`随机性规划`(Stochastic programming)

## 股票组合优化(portfolio optimization)

![image-20200718162619045](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718162619045.png)

M元资本,投入到n个股票中,使得期望收益最大.

![image-20200718162730222](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718162730222.png)

![image-20200718162751633](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718162751633.png)

$w_i$是第i支股票所占配资比重.

$s_i$是第i支股票股价的随机变量.

![image-20200718162829566](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718162829566.png)

使用过去一年十二个月的行情均值,作为$\gamma_i$股价的均值和$\sigma_i$股价标准差的估值.

![image-20200718163006991](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718163006991.png)

求使得$\sum{w_is_i}$期望最大的$W$.

![image-20200718163057893](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718163057893.png)

目标函数为:

![image-20200718163650222](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718163650222.png)

矢量形式:

![image-20200718163716707](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718163716707.png)

其中:

![image-20200718163738644](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718163738644.png)

这是一个典型的二次规划问题,convex quadratic programming,属于Mean-Variance portfolio optiimization.

![image-20200718164009208](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718164009208.png)

模型简化了实际问题的:

-   成本问题
-   买入问题(引入不确定性)
-   从3000支股票中选取50支,稀疏性问题![image-20200718164208343](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718164208343.png)

-   可以加入约束条件,要求某只股票一定被买入 ![image-20200718164258070](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718164258070.png)

![image-20200718164311356](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718164311356.png)

凸优化参考资料:

-   https://web.stanford.edu/~boyd/cvxbook/

多个正态分布的加权平均任然服从正态分布.

## Set Cover problem

集合覆盖问题:

![image-20200718164837252](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718164837252.png)

![image-20200718165142774](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718165142774.png)

1.  穷举法

    遍历所有可能的取值组合,直到找到解,指数时间复杂度

    ![image-20200718165235930](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718165235930.png)

2.  贪婪法

 ![image-20200718165418224](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718165418224.png)

有时可以给出最优解,有时给出的是次优解.

![image-20200718165619448](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718165619448.png)

从元素数量最多的集合出发,依次选取次多的集合做并集,当并集等于全集U时,算法结束.

数据结构与算法的扩展:

![image-20200718165756711](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718165756711.png)

3.  数学方法:![image-20200718170246450](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718170246450.png)

1.  确定变量

![image-20200718170317882](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718170317882.png)

2.确定目标:

![image-20200718170416714](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718170416714.png)

3.约束条件:

![image-20200718170436848](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718170436848.png)

4.优化目标:

![image-20200718170504031](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718170504031.png)

属于整数线性规划问题:![image-20200718170824407](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718170824407.png)

ILP是Non-convex的.

通过松弛问题Relaxation$=>$

![image-20200718171655602](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718171655602.png)

一般可以求得次优解,改进形式:

![image-20200718171731943](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718171731943.png)

凸优化算法库:cvxopt.org

## 对偶问题

### Lower bound property

把一个原始问题Primal 转化为对偶问题 duality

![image-20200718172644585](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718172644585.png)

![image-20200718172655077](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718172655077.png)

原始问题的解P*和对偶问题的解P\*满足 Lower bound property.

![image-20200718191122496](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718191122496.png)

原始问题和对偶问题是看待问题的不同角度。

有条件凸优化的标准形式：

![image-20200718191254923](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718191254923.png)

定义原始问题的$x^*$(最优解的参数取值)和$p^*$(最优解的值):

![image-20200718191946181](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718191946181.png)

由拉格朗日乘子法可得：

![image-20200718191404896](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718191404896.png)

其中:$\lambda \geq 0$

对偶形式是：

![image-20200718191530308](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718191530308.png)

-   inf 是infinum，下界，在此处可理解做min

![image-20200718191636971](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718191636971.png)

定理Lower bound property:

![image-20200718192152877](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718192152877.png)

 即无论参数$\lambda$和 $v$如何取值,g函数的最大值(d*)都小于原始问题最优解的值. 

![image-20200718192835374](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718192835374.png)

Dual gap :$P^* - \max g(\lambda,v)$

证明:![image-20200718193058032](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718193058032.png)

把一个最小化优化问题转化为最大化优化问题.

![image-20200718193622925](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718193622925.png)

![image-20200718193702206](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718193702206.png)

![image-20200718193819148](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718193819148.png)

相当于从最小化f和最大化g的角度,同时优化问题.

![image-20200718194029377](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718194029377.png)

对偶问题的特点:

![image-20200718193749861](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718193749861.png)

对偶函数是一个凹函数.

具体例子:

![image-20200718194306938](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718194306938.png)

通过gap的大小来反映当前值与真正最优解的近似程度.

![image-20200718194419275](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718194419275.png)

### Least Norm minimization

![image-20200718211201199](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718211201199.png)

使用拉格朗日乘子法：![image-20200718211226493](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718211226493.png)

对x求导：

![image-20200718211317636](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718211317636.png)

求得：

![image-20200718211405688](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718211405688.png)

对偶问题为

![image-20200718211500817](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718211500817.png)

代入上式，

![image-20200718211535738](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718211535738.png)

即![image-20200718211559140](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718211559140.png)

问题转化为：

$$ \inf P^* = \max \{-\frac{1}{4} V^{\top} AA^{\top} v-b\} $$

扩展：向量一般默认是列向量

### Linear Programming

$$\begin{aligned}
\text { minimize } & C^{\top} x \\
\text { s.t. } & A x=b \\
& x \geqslant 0
\end{aligned}$$

转化为

![image-20200718212429082](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718212429082.png)

应用拉格朗日乘子法:

![image-20200718212457047](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718212457047.png)

对x求导,求得驻点.

代入对偶函数:

![image-20200718212548350](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718212548350.png)

负无穷被称作uninformed minimum

对偶问题是

![image-20200718212734958](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718212734958.png)

### 强对偶性 和 弱对偶性



对于问题对:

![image-20200718212941582](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718212941582.png)

由Lower bound property可知:

![image-20200718213017892](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718213017892.png)

弱对偶性:

![image-20200718213159997](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718213159997.png)

强对偶性:

![image-20200718213211743](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718213211743.png)

满足:

![image-20200718213226600](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718213226600.png)

判断强对偶性存在的条件:

![image-20200718213405941](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718213405941.png)

### 互补、松弛性条件Complementary Slackness

假设满足强对偶性条件,x*是原始问题最优解,$\lambda ^ * 和v^ * $是对偶问题的最优解:

对于

![image-20200718214157742](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718214157742.png)

$$f_{0}\left(x^{*}\right) = g\left(x^{*}, v^{*}\right)=\inf _{x}\left[f_{\theta}(x)+\sum_{i=1}^{m} \lambda_{i}^{*} f_{i}(x)+\sum_{i=1}^{m} v_i h_{i}(x)\right] \Leftarrow\\ \begin{array}{l}
\leqslant f_{0}\left(x^{*}\right)+\sum_{i=1}^{m} \lambda_{i}^{*} f_{i}\left(x^{*}\right)(这一项<=0)+\sum_{i=1}^{P} V_{i}^{*} h_{i}\left(x^{*}\right)(最后一项=0) \\
\leqslant f_{0}\left(x^{*}\right)
\end{array}$$

![image-20200718215435455](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200718215435455.png)

被称作互补松弛性条件.

### KKT条件

延后至[SVM章节](#SVM支持向量机##KKT条件)





# 从词嵌入到文档距离

主讲:赵勇博士(中科大芜湖智慧城市研究院)

##摘要部分

![image-20200719154457975](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200719154457975.png)

![image-20200719154413110](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200719154413110.png)

![image-20200719154606750](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200719154606750.png)

![image-20200719154615869](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200719154615869.png)

![image-20200719155348266](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200719155348266.png)

## 引言



![image-20200719155637265](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200719155637265.png)

![image-20200719155706041](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200719155706041.png)

![image-20200719160307259](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200719160307259.png)

![image-20200719160431180](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200719160431180.png)

![image-20200719160509596](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200719160509596.png)

![image-20200719160533299](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200719160533299.png)

![image-20200719160635497](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200719160635497.png)

![image-20200719160650899](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200719160650899.png)

-   EWD也翻译作移土问题,推土机问题

![image-20200719160741775](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200719160741775.png)

引图:表达作者的主要思想.

图中obama 和president,press和media在语义Semantic上接近,伊利诺斯和芝加哥地理位置接近,也在语义上接近.

-   WMD距离的特性

![image-20200719162448160](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200719162448160.png)

###文档表示

![image-20200719172105833](https://i.loli.net/2020/07/19/QY5yxBCuIJwjiHM.png)

###### ![image-20200719172242555](https://i.loli.net/2020/07/19/SN8foucZyI3B6D2.png)

![image-20200719172333307](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200719172333307.png)

### Word2Vec

![image-20200722141929218](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722141929218.png)

![image-20200722141947021](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722141947021.png)

####CBOW对比Skip-Gram

![image-20200722142109241](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722142109241.png)

![image-20200722142119877](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722142119877.png)

![image-20200722142306866](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722142306866.png)

![image-20200722143436624](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722143436624.png)

![image-20200722144654247](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722144654247.png)

![image-20200722144711104](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722144711104.png)

![image-20200722144719693](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722144719693.png)

![image-20200722144805824](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722144805824.png)

通俗解释:在已知t的情况下能否把j预测出来

![image-20200722144824827](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722144824827.png)



![image-20200722145025146](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722145025146.png)

## 方法

### WMD

![image-20200722145158601](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722145158601.png)

$X_{d \times n} = [\matrix{x_1&x_2&...x_n]}=[\matrix{1&2&...n\\2&...&...n\\...&...&...\\d&d&d}]$

![image-20200722145210216](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722145210216.png)

$d_i = \frac{c_i}{\sum_{j=1}^n{c_j}}$

![image-20200722145410129](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722145410129.png)



![image-20200722145607250](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722145607250.png)





![image-20200722150610413](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722150610413.png)

#### 什么是EMD距离



![image-20200722150905002](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722150905002.png)

![image-20200722151002544](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722151002544.png)

#### WMD距离定义

![image-20200722151708793](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722151708793.png)

![image-20200722151721516](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722151721516.png)

将n个工厂的“货物“(Word2Vec权重)转移到m个工厂中的最少运输量.

$$\min _{\mathbf{T} \geq 0} \sum_{i, j=1}^{n} \mathbf{T}_{i j} c(i, j) \\
subject to:
\begin{array}{l}
\sum_{j=1}^{n} \mathbf{T}_{i j}=d_{i}, \forall i \in\{1, \cdots, n\} \\
\sum_{i=1}^{n} \mathbf{T}_{i j}=d_{j}^{\prime}, \forall j \in\{1, \cdots, n\}
\end{array}$$

![image-20200722152536245](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722152536245.png)

![image-20200722152709239](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722152709239.png)

###WMD距离快速计算

![image-20200722152850379](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722152850379.png)

![image-20200722152944531](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722152944531.png)

推导:

![image-20200722153024270](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722153024270.png)

![image-20200722153031834](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722153031834.png)

![image-20200722153126950](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722153126950.png)

不够紧致:WCD的下界偏小

#### 松弛移词距离(Relaxed Word Moving Distance)

发送货物不再考虑仓库是否容纳的下.

![image-20200722153332820](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722153332820.png)

![image-20200722153342073](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722153342073.png)

![image-20200722153546500](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722153546500.png)

![image-20200722153605134](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722153605134.png)

![image-20200722153709124](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722153709124.png)

### 预取与剪枝(prefetch and prune)

![image-20200722153757134](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722153757134.png)

![image-20200722154014008](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722154014008.png)

## 实验

![image-20200722154245088](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722154245088.png)

8个文档分类数据集

###比较方法:

![image-20200722154338437](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722154338437.png)

贝叶斯调参具有借鉴意义

![image-20200722154433993](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722154433993.png)

![image-20200722154445195](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722154445195.png)

LSI算法在结合贝叶斯调参之后,性能明显提升.

![image-20200722154455628](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722154455628.png)

实验中由于采用的嵌入方法没有超参数,主要的超参数是knn算法的$k$

![image-20200722154620175](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722154620175.png)

![image-20200722154635819](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722154635819.png)

应用预取\剪枝算法后:

![image-20200722154832083](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722154832083.png)

![image-20200722154842430](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722154842430.png)

## 总结

![image-20200722154929543](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722154929543.png)

![image-20200722154940438](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722154940438.png)

![image-20200722155718004](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722155718004.png)

![image-20200722155825169](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722155825169.png)

![image-20200722160012955](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722160012955.png)

###改进(WSMD)

![image-20200722160043238](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722160043238.png)

![image-20200722160129076](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722160129076.png)

![image-20200722160205691](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722160205691.png)

![image-20200722160230064](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722160230064.png)

![image-20200722160245309](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722160245309.png)

## 答疑

1.  每个词都是word2vec向量.

2.  文档是使用cbow+skip gram统计词频作为权重,词向量是d维空间中的点,文档就是d维空间中的权重点云.

3.  EMD的优化是一个数学过程.

![image-20200722161117507](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722161117507.png)

4.配货距离$T_{i,j}$如何理解:

A文档中的一个词i要改变多少才能成为B文档中的另外一个词j.

5.  一个单词是一个向量,一个文档就是一个矩阵或者集合,两片文档的距离就是词向量距离的加权.

6.  可以理解文章中的主要贡献就是把文档表示为词向量集合,然后提出一种带权重的测度去衡量集合间的距离或者相似度吗?

测度的三要素: 

距离和相似度的定义是有区别的,但是使用上可以相通.

7.  WMD的权重是不需要训练的,是通过无监督方法学习到的,转化为最优传输问题进行优化.

~~这一讲讲的很辣鸡，没听太懂~~

# SVM支持向量机

## KKT条件

###引入

对于原优化问题:

![image-20200722163622902](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722163622902.png)

![image-20200722163641114](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722163641114.png)

把有约束优化问题转化为无约束问题.

![image-20200722163719730](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722163719730.png)

![image-20200722163736269](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722163736269.png)

 若违反了原问题约束![image-20200722163921012](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722163921012.png)

则拉格朗日函数$l$的最大值 $\theta_p(w)$会趋近于正无穷。

![image-20200722165917383](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722165917383.png)

![image-20200722165934596](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722165934596.png) ![image-20200722170119673](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722170119673.png)

![image-20200722172243245](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722172243245.png)

![image-20200722172327137](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722172327137.png)

![image-20200722172500719](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722172500719.png)

![image-20200722172513057](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722172513057.png)

只有在满足kkt条件时，求出对偶问题的最优解，即是原问题的最优解。

![image-20200722172745667](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722172745667.png)

![image-20200722172838503](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722172838503.png)

在KKT条件下，$\alpha_i^*$和$g_i(w^*)$满足相乘为零的条件,dual complementarity.

在支持向量机中,$\alpha_i$指示一个向量是否是支持向量.



## SVM引入

![image-20200722202212250](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722202212250.png)

不同算法,不同判别标准有不同的最优解.

SVM的最优解:

![image-20200722202527073](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722202527073.png)

![image-20200722202624495](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722202624495.png)

svm是希望分类界面的间隔最大,因此也叫max-margin classifier.

### 向量的点积(投影)

![image-20200722202930854](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722202930854.png)



![image-20200722202757993](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722202757993.png)

两条分类界面的距离就是$(x_1,x_2)$向量在分类界面法线方向上的投影$(d_1+d_2)$.

![image-20200722203206164](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722203206164.png)

##svm数学模型

使得间隔越大越好,$\max\frac{1}{\|w\|_2}$

![image-20200722203935793](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722203935793.png)

变换约束条件,构造符合KTT条件的约束形式

![image-20200722204006791](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722204006791.png)

应用拉格朗日乘子法:

![image-20200722204039046](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722204039046.png)

![image-20200722204323543](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722204323543.png)

求出驻点并代入,

![image-20200722204338470](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722204338470.png)



![image-20200722204646342](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722204646342.png)

![image-20200722210313738](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722210313738.png)

在生产环境中做推理时,![image-20200722210803073](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722210803073.png)中大部分$\alpha$ = 0,只看和支持向量的间隔.

compact且sparse.

## 带松弛变量的软间隔支持向量机

![image-20200722211433691](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722211433691.png)

存在outlier,异常点.

处理方法:

1放松限制

![image-20200722211642014](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722211642014.png)

允许部分偏离点.

2.不放松限制

3.必须放松限制(处理线性不可分的情形)

![image-20200722213312092](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722213312092.png)

允许部分点跨过间隔.

###带松弛变量的SVM

![image-20200722213718740](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722213718740.png)

![image-20200722213947322](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722213947322.png)

### HInge Loss(合页损失函数)

![image-20200722214039077](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722214039077.png)

 

![image-20200722215411770](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722215411770.png)

Hinge-loss函数会“激烈反对”错分情况.

和logistic loss的区别:

被正确分类的情况(![image-20200722215557406](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722215557406.png)>1的情况),Hinge不会再进一步优化.

不会产生梯度爆炸.

**优点**

![image-20200722215722578](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722215722578.png)

### svm扩展内容

![image-20200722215805413](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722215805413.png)

将原有SVM最优化问题,通过拉格朗日算子,转化为一个新的最优化问题

![image-20200722215850407](C:\Users\admintrato\AppData\Roaming\Typora\typora-user-images\image-20200722215850407.png)

新增了

![image-20200722220223146](凸优化.assets/image-20200722220223146.png)

求导,代入驻点

![image-20200722220253281](凸优化.assets/image-20200722220253281.png)

![image-20200722220314563](凸优化.assets/image-20200722220314563.png)

### SVM的对偶形式

![image-20200722220339521](凸优化.assets/image-20200722220339521.png)

$x_i^Tx_j$就是$<x_i^T,x_j>$

即,![image-20200722220638191](凸优化.assets/image-20200722220638191.png)

所有属于正样本的权重和所有属于负样本的权重加起来应该是相等的.

## 核函数

![image-20200722220923512](凸优化.assets/image-20200722220923512.png)

###kernel SVM:

![image-20200722221019175](凸优化.assets/image-20200722221019175.png)

![image-20200722221054868](凸优化.assets/image-20200722221054868.png)

###使用核函数预测公式:

![image-20200722221149652](凸优化.assets/image-20200722221149652.png)

### 为什么要使用核函数:处理线性不可分情况

![image-20200722221242559](凸优化.assets/image-20200722221242559.png)

使用正确的核函数,可以处理线性不可分情况

把特征映射到更高的维度

![image-20200722221357617](凸优化.assets/image-20200722221357617.png)

把线性不可分映射到更高维度而可分

![image-20200722221404751](凸优化.assets/image-20200722221404751.png)

![image-20200722221740812](凸优化.assets/image-20200722221740812.png)

![image-20200722221832382](凸优化.assets/image-20200722221832382.png)

feature crossing

### 直接扩展到高维的问题

![image-20200722221908073](凸优化.assets/image-20200722221908073.png)

rbf核可以把数据映射到无限维:——Radial Basis Function（RBF）

所谓径向基函数 (Radial Basis Function 简称 RBF), 就是某种沿径向对称的标量函数。 通常定义为空间中任一点x到某

一中心xc之间欧氏距离的单调函数 ,可记作 $k(||x-xc||)$, 其作用往往是局部的 , 即当x远离xc时函数取值很小。



最常用的径向基函数是**高斯核函数** ,形式为$ k(||x-xc||)=exp{- ||x-xc||^2/(2*σ)^2) }$ 其中$x_c$为核函数中心,σ为函数的宽度参数 , 控制了函数的径向作用范围。如果x和x_c很相近那么核函数值为1，如果x和$x_c$相差很大那么核函数值约等于0。由于这个函数类似于高斯分布，因此称为高斯核函数，也叫做径向基函数(Radial Basis Function 简称RBF)。它能够把原始特征映射到无穷维。

那么核函数值约等于0。由于这个函数类似于高斯分布，因此称为高斯核函数，也叫做径向基函数(Radial Basis Function 简称RBF)。它能够把原始特征映射到无穷维。

既然高斯核函数能够比较x和z的相似度，并映射到0到1，回想logistic回归，sigmoid函数可以，因此还有sigmoid核函数等等。

### 核函数有效性判定

mercer’s theorem

![image-20200722222317171](凸优化.assets/image-20200722222317171.png)

### 常用核函数

![image-20200722222437669](凸优化.assets/image-20200722222437669.png)

![image-20200722222653614](凸优化.assets/image-20200722222653614.png)

![image-20200722222734937](凸优化.assets/image-20200722222734937.png)

![image-20200722222831555](凸优化.assets/image-20200722222831555.png)

![image-20200722223012149](凸优化.assets/image-20200722223012149.png)

sigmoid核:

![image-20200722223135689](凸优化.assets/image-20200722223135689.png)

余弦相似度核(cosine similarity):

![image-20200722223215145](凸优化.assets/image-20200722223215145.png)

可以是bert等embedding后的向量.

chi-squared 卡方核:

![image-20200722223331846](凸优化.assets/image-20200722223331846.png)

##求解SVM:

![image-20200722223826518](凸优化.assets/image-20200722223826518.png)

### 序贯法SMO

Coordinate Descent坐标轮换法:

![image-20200722223910315](凸优化.assets/image-20200722223910315.png)

![image-20200722223955160](凸优化.assets/image-20200722223955160.png)

![image-20200722224004892](凸优化.assets/image-20200722224004892.png)

![image-20200722224013141](凸优化.assets/image-20200722224013141.png)

![image-20200722224113199](凸优化.assets/image-20200722224113199.png)

### 应用到SVM

![image-20200722224200380](凸优化.assets/image-20200722224200380.png)

###SMO算法:![image-20200722224255018](凸优化.assets/image-20200722224255018.png)

![image-20200722224414417](凸优化.assets/image-20200722224414417.png)

![image-20200722224551981](凸优化.assets/image-20200722224551981.png)

![image-20200722224600287](凸优化.assets/image-20200722224600287.png)

![image-20200722231223737](凸优化.assets/image-20200722231223737.png)

![image-20200722231918157](凸优化.assets/image-20200722231918157.png)

### 多类别分类SVM

![image-20200722232417528](凸优化.assets/image-20200722232417528.png)

![image-20200722232523620](凸优化.assets/image-20200722232523620.png)

![image-20200722232532691](凸优化.assets/image-20200722232532691.png)

## 总结

![image-20200722232623391](凸优化.assets/image-20200722232623391.png)

## 核线性回归kernel linear regression

![image-20200722232828121](凸优化.assets/image-20200722232828121.png)

### 对偶形式的线性回归

![image-20200722233001877](凸优化.assets/image-20200722233001877.png)

![image-20200722232919621](凸优化.assets/image-20200722232919621.png)

![image-20200722232928014](凸优化.assets/image-20200722232928014.png)

### 径向基核线性回归

![image-20200722233249799](凸优化.assets/image-20200722233249799.png)

当$\gamma$较小时:对应rbf钟形曲线width较窄,易underfitting

## Kernel PCA

### 回顾PCA

![image-20200722233524647](凸优化.assets/image-20200722233524647.png)

![image-20200722233531681](凸优化.assets/image-20200722233531681.png)

![image-20200722233554052](凸优化.assets/image-20200722233554052.png)

![image-20200722234509862](凸优化.assets/image-20200722234509862.png)

![image-20200722234547024](凸优化.assets/image-20200722234547024.png)

![image-20200722234737964](凸优化.assets/image-20200722234737964.png)

![image-20200722234810286](凸优化.assets/image-20200722234810286.png)

![image-20200722235001535](凸优化.assets/image-20200722235001535.png)

### 步骤总结

![image-20200722235133917](凸优化.assets/image-20200722235133917.png)

###kernel PCA实例

![image-20200722235207196](凸优化.assets/image-20200722235207196.png)

![image-20200722235236556](凸优化.assets/image-20200722235236556.png)

## 交叉验证 Cross Validation

![image-20200722235507486](凸优化.assets/image-20200722235507486.png)

![image-20200722235514911](凸优化.assets/image-20200722235514911.png)

![image-20200722235619321](凸优化.assets/image-20200722235619321.png)

## VC维

### 理论

![image-20200722235807117](凸优化.assets/image-20200722235807117.png)

VC维实例:线性分类器的VC维为3

![image-20200722235942749](凸优化.assets/image-20200722235942749.png)

 VC维实例:圆框分类器的VC维为3

VC维实例:单层神经元无法处理异或问题

## SVR支持向量回归

暂缺

## 答疑

1.为什么拉格朗日函数约束不满足时，最大值$\theta_p$是无穷？

![image-20200723124513718](凸优化.assets/image-20200723124513718.png)

![image-20200723123949451](凸优化.assets/image-20200723123949451.png)

若$\exist g_i(w) > 0,l(w,\alpha,\beta)$并未限制$\alpha$的取值,$\alpha_i\rightarrow\infin$,则$l(w,\alpha,\beta) → ∞$

2.![image-20200723124330470](凸优化.assets/image-20200723124330470.png)

不会,在内层优化问题看来,w是常量

3.![image-20200723124433580](凸优化.assets/image-20200723124433580.png) 

原问题无法应用对偶问题带来的<$x_i^t,x_j$>的核技巧优势.

4.![image-20200723140753850](凸优化.assets/image-20200723140753850.png)

5.松弛问题之后,部分越过分类界面的点也可以成为支持向量.

6.正定函数

![image-20200723141126859](凸优化.assets/image-20200723141126859.png)

7.使用高斯核之前要进行正规化,去除量纲影响

8.rbf核也是只和支持向量作比较

9.SMO的停止条件就是找到KKT

10.SMO算法中可以使用启发式方法选择$\alpha$和$\beta$

11.核线性回归锚点的选取:

可以选取一些关键点,或者多个点的均值

锚点可以是数据点,也可以是随机点

锚点数量多可以更容易拟合

12.协方差矩阵的意义:

一个变量的变化和另外一个变量变化的关系

13.原始问题和对偶问题的关系:一个函数的max min总是小于等于min max

14.参考资料:

![image-20200723143332539](凸优化.assets/image-20200723143332539.png)

15.

![image-20200723143714417](凸优化.assets/image-20200723143714417.png)

不满足KKT条件的时候,不一定是最优解,但仍可能为解.

 

# 线性规划

![image-20200723144525169](凸优化.assets/image-20200723144525169.png)