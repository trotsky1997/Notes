# Denoising Diffusion Implicit Models
> [!info]+ <center>Metadata</center>
> 
> |<div style="width: 5em">Key</div>|Value|
> |--:|:--|
> |æ–‡çŒ®ç±»å‹|preprint|
> |æ ‡é¢˜|Denoising Diffusion Implicit Models|
> |çŸ­æ ‡é¢˜||
> |ä½œè€…|[[Jiaming Song]]ã€ [[Chenlin Meng]]ã€ [[Stefano Ermon]]|
> |æœŸåˆŠåç§°||
> |DOI||
> |å­˜æ¡£ä½ç½®||
> |é¦†è—ç›®å½•|arXiv.org|
> |ç´¢ä¹¦å·||
> |ç‰ˆæƒ||
> |åˆ†ç±»||
> |æ¡ç›®é“¾æ¥|[My Library](zotero://select/library/items/5ILZRRSP)|
> |PDF é™„ä»¶|[Song et al. - 2022 - Denoising Diffusion Implicit Models.pdf](zotero://open-pdf/library/items/CHRBA486)|
> |å…³è”æ–‡çŒ®||
> ^Metadata

> [!example]- <center>æœ¬æ–‡æ ‡ç­¾</center>
> 
> `$=dv.current().file.tags`

> [!quote]- <center>Abstract</center>
> 
> Denoising diffusion probabilistic models (DDPMs) have achieved high quality image generation without adversarial training, yet they require simulating a Markov chain for many steps to produce a sample. To accelerate sampling, we present denoising diffusion implicit models (DDIMs), a more efficient class of iterative implicit probabilistic models with the same training procedure as DDPMs. In DDPMs, the generative process is defined as the reverse of a Markovian diffusion process. We construct a class of non-Markovian diffusion processes that lead to the same training objective, but whose reverse process can be much faster to sample from. We empirically demonstrate that DDIMs can produce high quality samples $10 \times$ to $50 \times$ faster in terms of wall-clock time compared to DDPMs, allow us to trade off computation for sample quality, and can perform semantically meaningful image interpolation directly in the latent space.

> [!tldr]- <center>éšè—ä¿¡æ¯</center>
> 
> itemType:: preprint
> title:: Denoising Diffusion Implicit Models
> shortTitle:: 
> creators:: [[Jiaming Song]]ã€ [[Chenlin Meng]]ã€ [[Stefano Ermon]]
> publicationTitle:: 
> journalAbbreviation:: 
> volume:: 
> issue:: 
> pages:: 
> language:: 
> DOI:: 
> ISSN:: 
> url:: [http://arxiv.org/abs/2010.02502](http://arxiv.org/abs/2010.02502)
> archive:: 
> archiveLocation:: 
> libraryCatalog:: arXiv.org
> callNumber:: 
> rights:: 
> extra:: 132 citations (Semantic Scholar/arXiv) [2022-06-21] arXivï¼š2010.02502 [cs]; httpsï¼š//web.archive.org/web/20220621150925/httpsï¼š//arxiv.org/abs/2010.02502
> collection:: 
> tags:: #reading #Computer_Science_-_Computer_Vision_and_Pattern_Recognition #Computer_Science_-_Machine_Learning
> related:: 
> itemLink:: [My Library](zotero://select/library/items/5ILZRRSP)
> pdfLink:: [Song et al. - 2022 - Denoising Diffusion Implicit Models.pdf](zotero://open-pdf/library/items/CHRBA486)
> qnkey:: 2022_Song_Denoising Diffusion _KEY-5ILZRRSP
> date:: 2022-06-09
> dateY:: 2022
> dateAdded:: 2022-06-20
> dateModified:: 2023-07-07
> 
> abstract:: Denoising diffusion probabilistic models (DDPMs) have achieved high quality image generation without adversarial training, yet they require simulating a Markov chain for many steps to produce a sample. To accelerate sampling, we present denoising diffusion implicit models (DDIMs), a more efficient class of iterative implicit probabilistic models with the same training procedure as DDPMs. In DDPMs, the generative process is defined as the reverse of a Markovian diffusion process. We construct a class of non-Markovian diffusion processes that lead to the same training objective, but whose reverse process can be much faster to sample from. We empirically demonstrate that DDIMs can produce high quality samples $10 \times$ to $50 \times$ faster in terms of wall-clock time compared to DDPMs, allow us to trade off computation for sample quality, and can perform semantically meaningful image interpolation directly in the latent space.


%--------------Ï‰--------------%

## âœï¸ ç¬”è®°åŒº

> [!WARNING]+ <center>ğŸ£ æ€»ç»“</center>  
>
>ğŸ¯ ç ”ç©¶é—®é¢˜::  
ğŸ” ç ”ç©¶èƒŒæ™¯::  
ğŸš€ ç ”ç©¶æ–¹æ³•::  
ğŸ” ç ”ç©¶æ€è·¯::  
ğŸ“º ä¸»è¦å†…å®¹::  
ğŸ‰ ç ”ç©¶ç»“è®º::  
ğŸ—ï¸ åˆ›æ–°ç‚¹::  
ğŸ’© ç ”ç©¶å±€é™::  
ğŸ¾ ç ”ç©¶å±•æœ›::  
âœï¸ å¤‡æ³¨::  

> [!inbox]- <center>ğŸ“« å¯¼å…¥æ—¶é—´</center>
>
> â° importDate:: 2023-07-07

%--------------Ï‰--------------%

## ğŸ“ æ³¨é‡Šç¬”è®° CHRBA486

> <span style="font-size: 15px;color: gray">ğŸ“ 2022-Song-Denoising Diffusion Implicit Models</span>

^KEYrefTitle

> <span class="highlight" style="background-color: #ffd400">Denoising diffusion probabilistic models (DDPMs) have achieved high quality image generation without adversarial training, yet they require simulating a Markov chain for many steps in order to produce a sample. To accelerate sampling, we present denoising diffusion implicit models (DDIMs), a more efficient class of iterative implicit probabilistic models with the same training procedure as DDPMs. In DDPMs, the generative process is defined as the reverse of a particular Markovian diffusion process. We generalize DDPMs via a class of non-Markovian diffusion processes that lead to the same training objective. These non-Markovian processes can correspond to generative processes that are deterministic, giving rise to implicit models that produce high quality samples much faster. We empirically demonstrate that DDIMs can produce high quality samples 10Ã— to 50Ã— faster in terms of wall-clock time compared to DDPMs, allow us to trade off computation for sample quality, perform semantically meaningful image interpolation directly in the latent space, and reconstruct observations with very low error.</span>  
> ğŸ”¤å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹(DDPMs)å–å¾—äº†é«˜è´¨é‡å›¾åƒç”Ÿæˆæ²¡æœ‰å¯¹æŠ—çš„è®­ç»ƒ,ä½†ä»–ä»¬éœ€è¦æ¨¡æ‹Ÿä¸€ä¸ªé©¬å°”å¯å¤«é“¾å¯¹è®¸å¤šæ­¥éª¤,ä»¥äº§ç”Ÿä¸€ä¸ªæ ·æœ¬ã€‚åŠ é€ŸæŠ½æ ·,æˆ‘ä»¬ç°åœ¨å»å™ªæ‰©æ•£éšå¼æ¨¡å‹(DDIMs),æ›´æœ‰æ•ˆçš„è¿­ä»£éšå«æ¦‚ç‡æ¨¡å‹ä¸DDPMsä¸€æ ·çš„è®­ç»ƒè¿‡ç¨‹ã€‚DDPMs,ç”Ÿæˆè¿‡ç¨‹çš„å®šä¹‰æ˜¯åå‘çš„é©¬å°”å¯å¤«é“¾çš„æ‰©æ•£è¿‡ç¨‹ã€‚æˆ‘ä»¬é€šè¿‡ä¸€ç±»non-Markovianæ¦‚æ‹¬DDPMsæ‰©æ•£è¿‡ç¨‹,å¯¼è‡´åŒæ ·çš„è®­ç»ƒç›®æ ‡ã€‚è¿™äº›non-Markovianè¿‡ç¨‹å¯ä»¥å¯¹åº”äºç¡®å®šçš„ç”Ÿæˆè¿‡ç¨‹,å¼•èµ·éšå¼æ¨¡å‹,ç”Ÿäº§é«˜è´¨é‡çš„æ ·å“å¿«å¾—å¤šã€‚æˆ‘ä»¬ç»éªŒè¯æ˜DDIMså¯ä»¥äº§ç”Ÿé«˜è´¨é‡çš„æ ·å“å¿«10Ã—50Ã—æ‰€DDPMsç›¸æ¯”,å…è®¸æˆ‘ä»¬æƒè¡¡è®¡ç®—æ ·æœ¬è´¨é‡,ç›´æ¥æ‰§è¡Œè¯­ä¹‰ä¸Šæœ‰æ„ä¹‰çš„å›¾åƒæ’å€¼çš„æ½œåœ¨ç©ºé—´,å’Œé‡æ„è§‚æµ‹è¯¯å·®å¾ˆä½ã€‚ğŸ”¤ ([p1](zotero://open-pdf/library/items/CHRBA486?page=1&annotation=QSPCMC9A))

^KEYQSPCMC9A

> <span class="highlight" style="background-color: #ffd400">Recent works on iterative generative models</span>  
> ğŸ”¤è¿‘æœŸä½œå“åœ¨è¿­ä»£ç”Ÿæˆæ¨¡å‹ğŸ”¤ ([p1](zotero://open-pdf/library/items/CHRBA486?page=1&annotation=4824L42L))

^KEY4824L42L

> <span class="highlight" style="background-color: #ffd400">such as denoising diffusion probabilistic models</span>  
> ğŸ”¤å¦‚å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ğŸ”¤ ([p1](zotero://open-pdf/library/items/CHRBA486?page=1&annotation=5P365IAT))

^KEY5P365IAT

> <span class="highlight" style="background-color: #ffd400">have demonstrated the ability to produce samples comparable to that of GANs, without having to perform adversarial training.</span>  
> ğŸ”¤å·²ç»è¯æ˜èƒ½å¤Ÿç”Ÿäº§æ ·å“ä¸ç”˜æ–¯,æ— éœ€è¿›è¡Œå¯¹æŠ—è®­ç»ƒã€‚ğŸ”¤ ([p1](zotero://open-pdf/library/items/CHRBA486?page=1&annotation=ZL2MX7I4))

^KEYZL2MX7I4

> <span class="highlight" style="background-color: #ffd400">To achieve this, many denoising autoencoding models are trained to denoise samples corrupted by various levels of Gaussian noise. Samples are then produced by a Markov chain which, starting from white noise, progressively denoises it into an image.</span>  
> ğŸ”¤ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œè®¸å¤šå»å™ªè‡ªåŠ¨ç¼–ç æ¨¡å‹ç»è¿‡è®­ç»ƒï¼Œå¯ä»¥å¯¹è¢«ä¸åŒçº§åˆ«çš„é«˜æ–¯å™ªå£°ç ´åçš„æ ·æœ¬è¿›è¡Œå»å™ªã€‚ç„¶åï¼Œé©¬å°”å¯å¤«é“¾ç”Ÿæˆæ ·æœ¬ï¼Œè¯¥é“¾ä»ç™½å™ªå£°å¼€å§‹ï¼Œé€æ¸å°†å…¶å»å™ªä¸ºå›¾åƒã€‚ğŸ”¤ ([p1](zotero://open-pdf/library/items/CHRBA486?page=1&annotation=RFSVQUUL))

^KEYRFSVQUUL

> <span class="highlight" style="background-color: #ffd400">A critical drawback of these models is that they require many iterations to produce a high quality sample. For DDPMs, this is because that the generative process (from noise to data) approximates the reverse of the forward diffusion process (from data to noise), which could have thousands of steps; iterating over all the steps is required to produce a single sample, which is much slower compared to GANs, which only needs one pass through a network.</span>  
> ğŸ”¤è¿™äº›æ¨¡å‹çš„ä¸€ä¸ªå…³é”®ç¼ºç‚¹æ˜¯å®ƒä»¬éœ€è¦å¤šæ¬¡è¿­ä»£æ‰èƒ½äº§ç”Ÿé«˜è´¨é‡çš„æ ·æœ¬ã€‚å¯¹äº DDPMï¼Œè¿™æ˜¯å› ä¸ºç”Ÿæˆè¿‡ç¨‹ï¼ˆä»å™ªå£°åˆ°æ•°æ®ï¼‰è¿‘ä¼¼äºå‰å‘æ‰©æ•£è¿‡ç¨‹ï¼ˆä»æ•°æ®åˆ°å™ªå£°ï¼‰çš„é€†è¿‡ç¨‹ï¼Œåè€…å¯èƒ½æœ‰æ•°åƒä¸ªæ­¥éª¤ï¼›ç”Ÿæˆå•ä¸ªæ ·æœ¬éœ€è¦è¿­ä»£æ‰€æœ‰æ­¥éª¤ï¼Œè¿™æ¯”åªéœ€è¦é€šè¿‡ç½‘ç»œä¸€æ¬¡çš„ GAN æ…¢å¾—å¤šã€‚ğŸ”¤ ([p1](zotero://open-pdf/library/items/CHRBA486?page=1&annotation=CU6LAMJE))

^KEYCU6LAMJE

> <span class="highlight" style="background-color: #ffd400">his can massively increase sample efficiency only at a minor cost in sample quality.</span>  
> ğŸ”¤åªéœ€è¦ä»¥å¾ˆå°çš„æ ·å“è´¨é‡æˆæœ¬ä¸ºä»£ä»·ï¼Œå°±èƒ½å¤§å¹…æé«˜æ ·å“æ•ˆç‡ã€‚ğŸ”¤ ([p2](zotero://open-pdf/library/items/CHRBA486?page=2&annotation=TCATK9DG))

^KEYTCATK9DG

